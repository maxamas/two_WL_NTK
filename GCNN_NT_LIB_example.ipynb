{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"CLlHJB7YguRG","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1678883259015,"user_tz":-60,"elapsed":59198,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"f1575b6d-28f3-4d82-b22a-e3b335ab2e67"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/2.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: jaxlib==0.4.4 in /usr/local/lib/python3.9/dist-packages (0.4.4+cuda11.cudnn82)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from jaxlib==0.4.4) (1.22.4)\n","Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jaxlib==0.4.4) (1.10.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: jax 0.4.6 does not provide the extra 'cuda11_cudnn805'\u001b[0m\u001b[33m\n","\u001b[0m  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.8/112.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for neural-tangents (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cpu\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (0.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.25.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.10)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.0+cpu.html\n","Collecting pyg-lib\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/pyg_lib-0.1.0%2Bpt113cpu-cp39-cp39-linux_x86_64.whl (539 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.4/539.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_scatter-2.1.0%2Bpt113cpu-cp39-cp39-linux_x86_64.whl (491 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.7/491.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_sparse-0.6.16%2Bpt113cpu-cp39-cp39-linux_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_cluster-1.6.0%2Bpt113cpu-cp39-cp39-linux_x86_64.whl (706 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.6/706.6 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_spline_conv-1.2.1%2Bpt113cpu-cp39-cp39-linux_x86_64.whl (203 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-geometric\n","  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.24.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.25.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n","Collecting psutil>=5.8.0\n","  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=64378fe9a8de222c9ef39acee16fffc0df0866bbbdb0ce8a6f6bb7d78bae5270\n","  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n","Successfully built torch-geometric\n","Installing collected packages: torch-spline-conv, torch-scatter, pyg-lib, psutil, torch-sparse, torch-cluster, torch-geometric\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","Successfully installed psutil-5.9.4 pyg-lib-0.1.0+pt113cpu torch-cluster-1.6.0+pt113cpu torch-geometric-2.2.0 torch-scatter-2.1.0+pt113cpu torch-sparse-0.6.16+pt113cpu torch-spline-conv-1.2.1+pt113cpu\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{}}],"source":["!pip install -q --upgrade pip\n","!pip install jaxlib==0.4.4\n","!pip install -q --upgrade jax[cuda11_cudnn805] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n","!pip install -q git+https://www.github.com/google/neural-tangents\n","!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n","!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/Masterarbeit/two_WL_NTK"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uK2sSxecI3lt","executionInfo":{"status":"ok","timestamp":1678883324714,"user_tz":-60,"elapsed":21497,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"ec80e876-031c-4dd7-e1ce-929060b90e96"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Masterarbeit/two_WL_NTK\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2NaGfUJhg8NM","executionInfo":{"status":"ok","timestamp":1678883330909,"user_tz":-60,"elapsed":6204,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}}},"outputs":[],"source":["import neural_tangents as nt\n","from neural_tangents import stax\n","from jax import numpy as np\n","from jax import random\n","import jax\n","\n","from utils import *"]},{"cell_type":"code","source":["# define a toy 4x4 graph\n","# 0----3\n","# |    |\n","# 1----2\n","\n","\n","edge_list = np.array([[0,1],\n","                      [0,3],\n","                      [1,0],\n","                      [1,2],\n","                      [2,1],\n","                      [2,3],\n","                      [3,2],\n","                      [3,0]])\n","\n","A = to_dense(np.transpose(edge_list), 4)\n","print(A)\n","\n","node_features = np.array([[1,2,3,4,5,6,7],\n","                          [10,20,30,40,50,60,70],\n","                          [100,200,300,400,500,600,700],\n","                          [1000,2000,3000,4000,5000,6000,7000]])\n","\n","node_features = node_features * 1.0\n","\n","node_features\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"wHDdTgcKJAeo","executionInfo":{"status":"error","timestamp":1678808066235,"user_tz":-60,"elapsed":1048,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"033076ff-e92b-4610-8988-ced0c78b9103"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d516f068d516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                       [3,0]])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'to_dense' is not defined"]}]},{"cell_type":"code","source":[" expected = A @ node_features\n"," expected"],"metadata":{"id":"kubzoxmfOFwi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Simple example much like presented here: https://neural-tangents.readthedocs.io/en/latest/_autosummary/neural_tangents.stax.Aggregate.html#neural_tangents.stax.Aggregate\n","\n","The problem with this is, that we can not run convolution layer on this input shape?! We need to reshape the node features such that they have a channel dimension"],"metadata":{"id":"CCDGnSuaRlLe"}},{"cell_type":"code","source":["# reshape\n","# the node feature must be a n x 1 dimensional array, with a channel dim\n","\n","# add a batch dimension\n","x = np.expand_dims(node_features, 0)\n","\n","pattern = np.expand_dims(A, 0)\n","\n","print(pattern.shape)\n","print(x.shape)"],"metadata":{"id":"lBYzUNkEPjDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Aggregate(aggregate_axis=1, batch_axis=0, channel_axis=2)\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)"],"metadata":{"id":"9Ob41Y6KIkYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = apply_fn(params, x, pattern=pattern)\n","out == expected"],"metadata":{"id":"RTP3cWM2LEXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now with a channel dimension"],"metadata":{"id":"VeLWaWKvR6r6"}},{"cell_type":"code","source":["# reshape\n","# the node feature must be a n x 1 dimensional array, with a channel dim\n","\n","# add a batch dimension\n","x = np.expand_dims(node_features, 0)\n","\n","# add a dim to make the node features a n x 1 dimensional array\n","# with a channel dim\n","x = np.expand_dims(x, 2)\n","\n","pattern = np.expand_dims(A, 0)\n","pattern = np.expand_dims(pattern, 2)\n","pattern = np.expand_dims(pattern, 4)\n","\n","print(pattern.shape)\n","print(x.shape)"],"metadata":{"id":"akWqGEuzLW5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3),\n","    stax.Conv(1, (1,1), parameterization=\"standard\")\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)"],"metadata":{"id":"3s6zvhXANEVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set all weights to 1 for the convolution\n","params = ((), (np.ones(params[1][0].shape), None))"],"metadata":{"id":"9cfuvjViUa2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = apply_fn(params, x, pattern=pattern)\n","np.squeeze(out).shape"],"metadata":{"id":"1td3SNfHUHHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the convolution weights are all 1 => the output of the convlution is the sum of the output of the agg layer\n","out = apply_fn(params, x, pattern=pattern)\n","print(np.squeeze(out))\n","np.sum(expected, axis=1)"],"metadata":{"id":"UbWXKqdpTXq0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test the kernel function"],"metadata":{"id":"vMPeRJuZ82r6"}},{"cell_type":"code","source":["layer_wide = 16\n","# define a grap convolution network\n","init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(layer_wide, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    stax.Aggregate(aggregate_axis=(1, 2), batch_axis=0, channel_axis=3, implementation=\"DENSE\"),\n","    stax.Conv(layer_wide, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"DENSE\"),\n","    stax.Conv(layer_wide, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    stax.GlobalSumPool(),\n","    stax.Dense(1),\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)\n","\n","a = apply_fn(params, x, pattern=pattern)\n","k = kernel_fn(x, x, ('ntk', \"nngp\"), pattern=(pattern, pattern))\n","\n","print(k.ntk.shape)\n","print(k.nngp.shape)\n","print(x.shape)\n","print(pattern.shape)"],"metadata":{"id":"xfiVMBaF815m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now with spars pattern\n","The shape of the pattern is: batch x #edges x 1 x 2"],"metadata":{"id":"v63hDP3xTjAt"}},{"cell_type":"code","source":["# define a toy 4x4 graph\n","# 0----3\n","# |    |\n","# 1----2\n","\n","\n","edge_list = np.array([[0,1],\n","                      [0,3],\n","                      [1,0],\n","                      [1,2],\n","                      [2,1],\n","                      [2,3],\n","                      [3,2],\n","                      [3,0]])\n","\n","node_features = np.array([[1,2,3,4,5,6,7],\n","                          [10,20,30,40,50,60,70],\n","                          [100,200,300,400,500,600,700],\n","                          [1000,2000,3000,4000,5000,6000,7000]])\n","\n","node_features = node_features * 1.0\n","\n","A = np.array([[0,1,0,1],\n","              [1,0,1,0],\n","              [0,1,0,1],\n","              [1,0,1,0]])\n","\n","expected = A @ node_features\n","\n","print(expected)\n","\n","node_features\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ti0u0Q9wt2l","executionInfo":{"status":"ok","timestamp":1678809590271,"user_tz":-60,"elapsed":318,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"3a7d816f-9f85-4b4d-a086-e9458657f312"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1010. 2020. 3030. 4040. 5050. 6060. 7070.]\n"," [ 101.  202.  303.  404.  505.  606.  707.]\n"," [1010. 2020. 3030. 4040. 5050. 6060. 7070.]\n"," [ 101.  202.  303.  404.  505.  606.  707.]]\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([[1.e+00, 2.e+00, 3.e+00, 4.e+00, 5.e+00, 6.e+00, 7.e+00],\n","       [1.e+01, 2.e+01, 3.e+01, 4.e+01, 5.e+01, 6.e+01, 7.e+01],\n","       [1.e+02, 2.e+02, 3.e+02, 4.e+02, 5.e+02, 6.e+02, 7.e+02],\n","       [1.e+03, 2.e+03, 3.e+03, 4.e+03, 5.e+03, 6.e+03, 7.e+03]],      dtype=float32, weak_type=True)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# reshape\n","# the node feature must be a n x 1 dimensional array, with a channel dim\n","\n","# add a batch dimension\n","x = np.expand_dims(node_features, 0)\n","\n","# add a dim to make the node features a n x 1 dimensional array\n","# with a channel dim\n","x = np.expand_dims(x, 2)\n","\n","pattern = np.expand_dims(edge_list, 0)\n","pattern = np.expand_dims(pattern, 2)\n","\n","print(pattern.shape)\n","print(x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yaq8bWosTm0o","executionInfo":{"status":"ok","timestamp":1678809592832,"user_tz":-60,"elapsed":239,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"b0cdbad5-c02c-42f3-8dbd-d5c29d5deb3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8, 1, 2)\n","(1, 4, 1, 7)\n"]}]},{"cell_type":"code","source":["# need to add a copy at axis 2 to make the argegation over axis (1,2) work\n","# need to aggreagte over axis (1,2) to keep the shape of the kernel stable in the aggregation layer\n","pattern = np.append(pattern, pattern, axis=2)\n","print(pattern.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdcgZOQwA7ct","executionInfo":{"status":"ok","timestamp":1678809596110,"user_tz":-60,"elapsed":246,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"07520002-7f6e-4e40-fcb4-0ac406f83339"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8, 2, 2)\n"]}]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\")\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)"],"metadata":{"id":"IIyeWc1uXgp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = apply_fn(params, x, pattern=pattern)\n","print(out.shape)\n","np.squeeze(out) == expected"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8nmWfesXmlQ","executionInfo":{"status":"ok","timestamp":1678809602226,"user_tz":-60,"elapsed":232,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"bb1131ea-eb74-46be-b85b-6aea14a930ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 4, 1, 7)\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([[ True,  True,  True,  True,  True,  True,  True],\n","       [ True,  True,  True,  True,  True,  True,  True],\n","       [ True,  True,  True,  True,  True,  True,  True],\n","       [ True,  True,  True,  True,  True,  True,  True]], dtype=bool)"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["Add conv layer"],"metadata":{"id":"pLXiSWbduuj0"}},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(1, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)"],"metadata":{"id":"4yKzZvZCZlcN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set all weights to 1 for the convolution\n","params = [(np.ones(params[0][0].shape), None), (), ()]"],"metadata":{"id":"zu-X_Db_Zr_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the convolution weights are all 1 => the output of the convlution is the sum of the output of the agg layer\n","out = apply_fn(params, x, pattern=pattern)\n","print(np.squeeze(out))\n","np.sum(expected, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaekRbqBBeH5","executionInfo":{"status":"ok","timestamp":1678810342435,"user_tz":-60,"elapsed":237,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"1765ce69-a225-48c2-c1aa-7ffd51cfd2de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[28280.  2828. 28280.  2828.]\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([28280.,  2828., 28280.,  2828.], dtype=float32)"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(10, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    stax.GlobalSumPool(),\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)\n","\n","# set all weights to 1 for the convolution\n","params = [(np.ones(params[0][0].shape), None), (), ()]"],"metadata":{"id":"dFRHOlZp5HKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the convolution weights are all 1 => the output of the convlution is the sum of the output of the agg layer\n","out = apply_fn(params, x, pattern=pattern)\n","print(np.squeeze(out))\n","np.sum(expected, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YX11vsdk5Kg4","executionInfo":{"status":"ok","timestamp":1678810355809,"user_tz":-60,"elapsed":331,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"6baf1545-844a-42f8-e86a-5736e5329830"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[62216. 62216. 62216. 62216. 62216. 62216. 62216. 62216. 62216. 62216.]\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([28280.,  2828., 28280.,  2828.], dtype=float32)"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["pattern"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5i-bapJ5ZZL","executionInfo":{"status":"ok","timestamp":1678810393409,"user_tz":-60,"elapsed":398,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"bfd93234-1ed7-4e17-f4af-cbe18f757821"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Array([[[[0, 1],\n","         [0, 1]],\n","\n","        [[0, 3],\n","         [0, 3]],\n","\n","        [[1, 0],\n","         [1, 0]],\n","\n","        [[1, 2],\n","         [1, 2]],\n","\n","        [[2, 1],\n","         [2, 1]],\n","\n","        [[2, 3],\n","         [2, 3]],\n","\n","        [[3, 2],\n","         [3, 2]],\n","\n","        [[3, 0],\n","         [3, 0]]]], dtype=int32)"]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","source":["Test the kernel function:"],"metadata":{"id":"raf2cTWAuxwP"}},{"cell_type":"code","source":["pattern = np.append(pattern, pattern, axis=2)"],"metadata":{"id":"Ej8xHobvAoLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pattern.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSW46wrwyEAu","executionInfo":{"status":"ok","timestamp":1678809552384,"user_tz":-60,"elapsed":231,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"7c91de68-4b09-4b44-aaca-110c02922d6f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 8, 2, 2)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["print(x.shape)\n","print(pattern.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9vPqjc5ydyP","executionInfo":{"status":"ok","timestamp":1678809556913,"user_tz":-60,"elapsed":236,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"4428a5e2-770d-4f31-cd80-287c6665a746"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 4, 1, 7)\n","(1, 8, 2, 2)\n"]}]},{"cell_type":"code","source":["x = np.swapaxes(x, 0, 1)\n","pattern = np.swapaxes(pattern, 0, 1)\n","\n","print(x.shape)\n","print(pattern.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWyGlMXcyfjF","executionInfo":{"status":"ok","timestamp":1678808645002,"user_tz":-60,"elapsed":12,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"3dfe46d8-7934-4cef-c0db-b805c088fc87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 1, 1, 7)\n","(8, 1, 2, 2)\n"]}]},{"cell_type":"code","source":["layer_wide = 16\n","# define a grap convolution network\n","init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(layer_wide, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    stax.Conv(layer_wide, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    stax.Conv(layer_wide, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    # stax.GlobalSumPool(),\n","    # stax.Dense(1),\n",")\n","\n","\n","print(x.shape)\n","print(pattern.shape)\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)\n","\n","a = apply_fn(params, x, pattern=pattern)\n","k = kernel_fn(x, x, ('ntk', \"nngp\"), pattern=(pattern, pattern))\n","\n","print(k.ntk.shape)\n","print(k.nngp.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TElOEKNJvqJq","executionInfo":{"status":"ok","timestamp":1678809826681,"user_tz":-60,"elapsed":878,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"fb3d9a83-a103-4ece-a61e-653fe2b0bf54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 4, 1, 7)\n","(1, 8, 2, 2)\n","(1, 1, 1, 1, 4, 4)\n","(1, 1, 1, 1, 4, 4)\n"]}]},{"cell_type":"code","source":["pattern.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnjNTxY93fHm","executionInfo":{"status":"ok","timestamp":1678809901419,"user_tz":-60,"elapsed":687,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"d412f5ea-a64e-4954-9893-49479283da0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 8, 2, 2)"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["# spars edge lists two graphs example"],"metadata":{"id":"b0h281bpPxDx"}},{"cell_type":"code","source":["# define a toy 4x4 graph\n","# 0----3\n","# |    |\n","# 1----2\n","# and 2x2 graph\n","# 0----1\n","\n","edge_list_1 = np.array([[0,1],\n","                      [0,3],\n","                      [1,0],\n","                      [1,2],\n","                      [2,1],\n","                      [2,3],\n","                      [3,2],\n","                      [3,0]])\n","\n","node_features_1 = np.array([[1,2],\n","                          [11,12],\n","                          [21,22],\n","                          [31,32]])\n","\n","node_features_1 = node_features_1 * 1.0\n","\n","edge_list_2 = np.array([[0,1],\n","                        [1,0],\n","                        [0,0],\n","                        [1,1]]) + 4\n","\n","node_features_2 = np.array([[1,2],\n","                          [21,22]])\n","\n","node_features_2 = node_features_2 * 1.0 \n","\n","graph_indx = np.append(np.full(node_features_1.shape[0], 0), np.full(node_features_2.shape[0], 1), 0)\n","edge_list = np.append(edge_list_1, edge_list_2, 0)\n","node_features = np.append(node_features_1, node_features_2, 0)\n","\n","print(graph_indx.shape)\n","print(edge_list.shape)\n","print(node_features.shape)\n","\n","node_features = np.expand_dims(node_features, 0)\n","node_features = np.expand_dims(node_features, 2)\n","\n","# need this to be able to aggregat over both axis, which we need for the kernel function to work\n","edge_list = np.expand_dims(edge_list, 0)\n","edge_list = np.expand_dims(edge_list, 2)\n","edge_list = np.append(edge_list, edge_list, axis=2)\n","\n","print(edge_list.shape)\n","print(node_features.shape)\n","\n","edge_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Juc4GTGhP3X-","executionInfo":{"status":"ok","timestamp":1678893563339,"user_tz":-60,"elapsed":6,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"0e80a28a-1bbf-40df-fb77-563d509b1610"},"execution_count":203,"outputs":[{"output_type":"stream","name":"stdout","text":["(6,)\n","(12, 2)\n","(6, 2)\n","(1, 12, 2, 2)\n","(1, 6, 1, 2)\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([[[[0, 1],\n","         [0, 1]],\n","\n","        [[0, 3],\n","         [0, 3]],\n","\n","        [[1, 0],\n","         [1, 0]],\n","\n","        [[1, 2],\n","         [1, 2]],\n","\n","        [[2, 1],\n","         [2, 1]],\n","\n","        [[2, 3],\n","         [2, 3]],\n","\n","        [[3, 2],\n","         [3, 2]],\n","\n","        [[3, 0],\n","         [3, 0]],\n","\n","        [[4, 5],\n","         [4, 5]],\n","\n","        [[5, 4],\n","         [5, 4]],\n","\n","        [[4, 4],\n","         [4, 4]],\n","\n","        [[5, 5],\n","         [5, 5]]]], dtype=int32)"]},"metadata":{},"execution_count":203}]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, node_features.shape)\n","\n","# set all weights to 1 for the convolution\n","params = [(np.ones(params[0][0].shape), None), (), ()]"],"metadata":{"id":"tB2gFufFRTfM","executionInfo":{"status":"ok","timestamp":1678893571914,"user_tz":-60,"elapsed":8,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}}},"execution_count":204,"outputs":[]},{"cell_type":"code","source":["out = apply_fn(params, node_features, pattern=edge_list)\n","print(out.shape)\n","np.squeeze(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PVguRp0RXap","executionInfo":{"status":"ok","timestamp":1678893576248,"user_tz":-60,"elapsed":250,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"97f5c24e-c330-4b9b-b5eb-e0ab8d39e982"},"execution_count":205,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 6, 1, 5)\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([[86., 86., 86., 86., 86.],\n","       [46., 46., 46., 46., 46.],\n","       [86., 86., 86., 86., 86.],\n","       [46., 46., 46., 46., 46.],\n","       [46., 46., 46., 46., 46.],\n","       [46., 46., 46., 46., 46.]], dtype=float32)"]},"metadata":{},"execution_count":205}]},{"cell_type":"code","source":["edge_list.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PENbouTC0Ra1","executionInfo":{"status":"ok","timestamp":1678892937207,"user_tz":-60,"elapsed":243,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"4cb5e5e0-898d-42d0-b834-c975be9876da"},"execution_count":180,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 12, 2)"]},"metadata":{},"execution_count":180}]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n",")\n","\n","\n","k = kernel_fn(node_features, node_features, ('ntk'), pattern=(edge_list, edge_list))\n","np.squeeze(k).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m9bTLc3zm83","executionInfo":{"status":"ok","timestamp":1678893639938,"user_tz":-60,"elapsed":1566,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"eb3adaca-bb1e-4541-db9d-a7f1dfd8b84d"},"execution_count":208,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 6)"]},"metadata":{},"execution_count":208}]},{"cell_type":"code","source":["a = np.array([1,2,3])\n","b = np.array([10,20,30])\n","\n","np.transpose(np.array([a,b]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Oa_3KouJUTv","executionInfo":{"status":"ok","timestamp":1678898481911,"user_tz":-60,"elapsed":896,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"a1d9e9b2-1603-40d1-a16c-82f63c8d3d3d"},"execution_count":274,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Array([[ 1, 10],\n","       [ 2, 20],\n","       [ 3, 30]], dtype=int32)"]},"metadata":{},"execution_count":274}]},{"cell_type":"code","source":["from typing import Callable, Iterable, Optional, Sequence, Tuple, Union\n","from neural_tangents import Kernel\n","from neural_tangents._src.stax.requirements import (\n","    Bool,\n","    Diagonal,\n","    get_diagonal_outer_prods,\n","    layer,\n","    mean_and_var,\n","    requires,\n","    supports_masking,\n",")\n","\n","\n","@layer\n","@supports_masking(remask_kernel=False)\n","def index_aggregation():\n","  init_fn = lambda rng, input_shape: (input_shape, ())\n","\n","  def apply_fn(\n","        params, inputs: np.ndarray, *, pattern: Optional[np.ndarray] = None,\n","        graph_indx: Optional[np.ndarray] = None, \n","        nb_graphs: Optional[int] = None,\n","        **kwargs\n","    ):\n","\n","    return np.apply_along_axis(lambda x: jax.ops.segment_sum(x, graph_indx, num_segments=nb_graphs), 0, np.squeeze(inputs))\n","\n","  def kernel_fn(\n","        k: Kernel,\n","        *,\n","        pattern: Tuple[Optional[np.ndarray], Optional[np.ndarray]] = (None, None),\n","        graph_indx: Tuple[Optional[np.ndarray], Optional[np.ndarray]] = (None, None),\n","        nb_graphs: Tuple[Optional[int], Optional[int]] = (None, None),\n","        **kwargs\n","    ):\n","\n","    def agg(x, kernel_graph_indx):\n","      agg_x = jax.ops.segment_sum(np.reshape(x, (-1)), kernel_graph_indx, num_segments=nb_graphs[0]*nb_graphs[1])\n","      agg_x = np.reshape(agg_x, nb_graphs)\n","      agg_x = np.expand_dims(agg_x, 0)\n","      agg_x = np.expand_dims(agg_x, 0)\n","      return agg_x\n","\n","    k_prod_graph_indx = row_wise_karthesian_prod(np.expand_dims(graph_indx[0], 1), np.expand_dims(graph_indx[1], 1))\n","    kernel_graph_indx = np.ravel_multi_index([k_prod_graph_indx[:,0], k_prod_graph_indx[:,1]], nb_graphs)\n","\n","    # Todo:\n","    # Do I need to calculate the cov1, cov2 too?\n","\n","    agg_ntk = agg(k.ntk, kernel_graph_indx)\n","    agg_nngp = agg(k.nngp, kernel_graph_indx)\n","    \n","    return k.replace(ntk=agg_ntk, nngp=agg_nngp, is_gaussian=True, is_input=False, \n","                     channel_axis=1)\n","\n","  return init_fn, apply_fn, kernel_fn\n","  \n"],"metadata":{"id":"y88bFpqiXv53","executionInfo":{"status":"ok","timestamp":1678897318389,"user_tz":-60,"elapsed":313,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}}},"execution_count":271,"outputs":[]},{"cell_type":"markdown","source":["## Test the apply function"],"metadata":{"id":"-5sLmP1y63mu"}},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    index_aggregation(),\n","    # stax.Dense(1)\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, node_features.shape)\n","params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyW47AGbYt7X","executionInfo":{"status":"ok","timestamp":1678893861342,"user_tz":-60,"elapsed":344,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"174c49d0-ddc2-4117-f09d-c7a8e7814280"},"execution_count":218,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/neural_tangents/_src/stax/linear.py:439: UserWarning: Negative indices in `pattern` are considered as padding (i.e. ignored), unlike typical numpy negative indexing.\n","  warnings.warn('Negative indices in `pattern` are considered as padding '\n"]},{"output_type":"execute_result","data":{"text/plain":["[(Array([[[[-1.2358007 ,  1.0902201 , -0.17007037, -0.12051605,\n","             0.8951071 ],\n","           [ 0.20728225, -0.6802286 ,  0.16402271,  0.60656357,\n","             0.7451222 ]]]], dtype=float32), None), (), ()]"]},"metadata":{},"execution_count":218}]},{"cell_type":"code","source":["# set all weights to 1 for the convolution\n","params[0] = (np.ones(params[0][0].shape), None)\n","params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gn5bqYQPo45R","executionInfo":{"status":"ok","timestamp":1678893863372,"user_tz":-60,"elapsed":11,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"271d1c6f-226e-4992-9cac-71a531296b9a"},"execution_count":219,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(Array([[[[1., 1., 1., 1., 1.],\n","           [1., 1., 1., 1., 1.]]]], dtype=float32), None), (), ()]"]},"metadata":{},"execution_count":219}]},{"cell_type":"code","source":["out = apply_fn(params, node_features, pattern=edge_list, graph_indx=graph_indx)\n","print(out.shape)\n","np.squeeze(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60fNu__DZGHv","executionInfo":{"status":"ok","timestamp":1678893867304,"user_tz":-60,"elapsed":975,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"ceb0df0c-8500-40e9-832c-29e4302557b3"},"execution_count":220,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 5)\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([[264., 264., 264., 264., 264.],\n","       [ 92.,  92.,  92.,  92.,  92.]], dtype=float32)"]},"metadata":{},"execution_count":220}]},{"cell_type":"markdown","source":["## Test the kernel function"],"metadata":{"id":"2NHekLUr68kK"}},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    # index_aggregation(),\n","    # stax.Dense(1)\n",")\n","\n","k = kernel_fn(node_features, node_features, ('ntk'), pattern=(edge_list, edge_list), graph_indx=graph_indx)\n","np.squeeze(k).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtMjW9K339gH","executionInfo":{"status":"ok","timestamp":1678893914992,"user_tz":-60,"elapsed":270,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"ef0bee7d-29d4-47d0-8b10-23845a90c604"},"execution_count":221,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 6)"]},"metadata":{},"execution_count":221}]},{"cell_type":"code","source":["# this is the expected result of the kernel function of the index_aggregation\n","# the input has 2 graphs => the kernel is a 2x2 array\n","# the layer bevor the aggregation is 6x6 (because 6 nodes in input)\n","# the first 4 nodes are from graph one => the sum of the 4x4 upper left block matrix is the \"self kernel\" of graph 1\n","# the las 2 nodes are from graph two => the sum of the 2x2 lower right block matrix is the \"self kernel\" of graph 2\n","# the ramaining 2x4 and 4x2 block matricies are the kernel of graph 1 graph 2 and vice versa\n","kernel = np.squeeze(k)\n","print(np.sum(kernel[:4,:4]))\n","print(np.sum(kernel[-2:,-2:]))\n","print(np.sum(kernel[:4,-2:]))\n","print(np.sum(kernel[:-2,4:]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QaLq6XB25iPs","executionInfo":{"status":"ok","timestamp":1678894447357,"user_tz":-60,"elapsed":725,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"187e7b6d-8412-448e-a683-d77cad0f1627"},"execution_count":242,"outputs":[{"output_type":"stream","name":"stdout","text":["34880.0\n","4240.0\n","12160.0\n","12160.0\n"]}]},{"cell_type":"code","source":["# now with the aggregation\n","# results match the expectation\n","init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    index_aggregation(),\n","    # stax.Dense(1)\n",")\n","\n","k = kernel_fn(node_features, node_features, ('ntk'), pattern=(edge_list, edge_list), graph_indx=(graph_indx, graph_indx), nb_graphs=(2,2))\n","k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"595Y_thfAWU5","executionInfo":{"status":"ok","timestamp":1678896103123,"user_tz":-60,"elapsed":616,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"2c7d3aba-c3f1-4b8b-d421-2139b7afbe22"},"execution_count":268,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Array([[[[34880., 12160.],\n","         [12160.,  4240.]]]], dtype=float32)"]},"metadata":{},"execution_count":268}]},{"cell_type":"code","source":["# now with the aggregation\n","# after the dense layer\n","init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(5, (1,1), parameterization=\"standard\"),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    index_aggregation(),\n","    stax.Dense(1)\n",")\n","\n","k = kernel_fn(node_features, node_features, ('ntk'), pattern=(edge_list, edge_list), graph_indx=(graph_indx, graph_indx), nb_graphs=(2,2))\n","k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BveMyDPd4GEh","executionInfo":{"status":"ok","timestamp":1678897327685,"user_tz":-60,"elapsed":998,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"b72f1664-26db-4b85-a2b8-369a304f60bf"},"execution_count":272,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Array([[[[52320., 18240.],\n","         [18240.,  6360.]]]], dtype=float32)"]},"metadata":{},"execution_count":272}]},{"cell_type":"markdown","source":["# Batches of spars edge lists"],"metadata":{"id":"5SpZL61a88B6"}},{"cell_type":"code","source":["# define a toy 4x4 graph\n","# 0----3\n","# |    |\n","# 1----2\n","# and 2x2 graph\n","# 0----1\n","\n","edge_list_1 = np.array([[0,1],\n","                      [0,3],\n","                      [1,0],\n","                      [1,2],\n","                      [2,1],\n","                      [2,3],\n","                      [3,2],\n","                      [3,0]])\n","\n","node_features_1 = np.array([[1,2,3,4,5,6,7],\n","                          [10,20,30,40,50,60,70],\n","                          [100,200,300,400,500,600,700],\n","                          [1000,2000,3000,4000,5000,6000,7000]])\n","\n","node_features_1 = node_features_1 * 1.0\n","\n","edge_list_2 = np.array([[0,1]])\n","\n","node_features_2 = np.array([[1,2,3,4,5,6,7],\n","                          [10,20,30,40,50,60,70]])\n","\n","node_features_2 = node_features_2 * 1.0\n","\n","\n","edge_list = np.expand_dims(edge_list_1, 0)\n","edge_list_2_zeros = np.zeros(edge_list_1.shape)\n","edge_list_2_zeros = edge_list_2_zeros.at[:edge_list_2.shape[0],:edge_list_2.shape[1]].set(edge_list_2)\n","edge_list_2_zeros = np.expand_dims(edge_list_2_zeros, 0)\n","edge_list = np.append(edge_list, edge_list_2_zeros, 0)\n","\n","\n","node_features = np.expand_dims(node_features_1, 0)\n","node_features_2_zeros = np.zeros(node_features_1.shape)\n","node_features_2_zeros = node_features_2_zeros.at[:node_features_2.shape[0],:node_features_2.shape[1]].set(node_features_2)\n","node_features_2_zeros = np.expand_dims(node_features_2_zeros, 0)\n","node_features = np.append(node_features, node_features_2_zeros, 0)\n","node_features = np.expand_dims(node_features, 2)\n","\n","pattern = edge_list\n","pattern = np.expand_dims(pattern, -1)\n","pattern = np.append(pattern, pattern, axis=-1)\n","pattern = np.array(pattern, dtype=\"int32\")\n","print(pattern.shape)\n","print(node_features.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZqx584r9Dgn","executionInfo":{"status":"ok","timestamp":1678812435308,"user_tz":-60,"elapsed":859,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"e056b021-6a00-4845-f762-d84b615d6893"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 8, 2, 2)\n","(2, 4, 1, 7)\n"]}]},{"cell_type":"code","source":["init_fn, apply_fn, kernel_fn = stax.serial(\n","    stax.Conv(10, (1,1), parameterization=\"ntk\"), stax.Relu(),\n","    stax.Aggregate(aggregate_axis=(1,2), batch_axis=0, channel_axis=3, implementation=\"SPARSE\"),\n","    # stax.GlobalSumPool(),\n","    # stax.Dense(1)\n",")\n","\n","key = random.PRNGKey(0)\n","key, subkey = jax.random.split(key)\n","_, params = init_fn(subkey, x.shape)"],"metadata":{"id":"NxYfmeK5__Rp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = apply_fn(params, node_features, pattern=pattern)\n","print(out.shape)\n","np.squeeze(out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIw8OKgtAZ4v","executionInfo":{"status":"ok","timestamp":1678812807703,"user_tz":-60,"elapsed":323,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}},"outputId":"e18dac34-7fa4-49cd-cddb-1dde6767db54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 4, 1, 10)\n"]},{"output_type":"execute_result","data":{"text/plain":["Array([[[0.0000000e+00, 2.9890306e+00, 5.7539976e-01, 1.0779002e+01,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.0347910e+00,\n","         1.8533856e+00, 1.0105654e+01],\n","        [0.0000000e+00, 2.9890301e+01, 5.7540030e+00, 1.0779002e+02,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.0347908e+01,\n","         1.8533855e+01, 1.0105654e+02],\n","        [0.0000000e+00, 2.9890305e+02, 5.7540031e+01, 1.0779003e+03,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.0347913e+02,\n","         1.8533858e+02, 1.0105653e+03],\n","        [0.0000000e+00, 2.9890312e+03, 5.7540045e+02, 1.0779003e+04,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.0347910e+03,\n","         1.8533855e+03, 1.0105653e+04]],\n","\n","       [[0.0000000e+00, 1.1956122e+01, 2.3015993e+00, 4.3116005e+01,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.2139164e+01,\n","         7.4135427e+00, 4.0422611e+01],\n","        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","         0.0000000e+00, 0.0000000e+00],\n","        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","         0.0000000e+00, 0.0000000e+00],\n","        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","         0.0000000e+00, 0.0000000e+00]]], dtype=float32)"]},"metadata":{},"execution_count":131}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}