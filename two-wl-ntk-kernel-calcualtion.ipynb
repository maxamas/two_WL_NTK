{"cells":[{"cell_type":"code","execution_count":null,"id":"NU1dqrN_Z7wE","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":63268,"status":"ok","timestamp":1676833756904,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"NU1dqrN_Z7wE","outputId":"ba042041-b8e2-4b78-c98f-d4e76bd1511c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: jax 0.4.4 does not provide the extra 'cuda11_cudnn805'\u001b[0m\u001b[33m\n","\u001b[0m  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for neural-tangents (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cpu\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.24.2)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.0+cpu.html\n","Collecting pyg-lib\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/pyg_lib-0.1.0%2Bpt113cpu-cp38-cp38-linux_x86_64.whl (539 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.3/539.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_scatter-2.1.0%2Bpt113cpu-cp38-cp38-linux_x86_64.whl (491 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_sparse-0.6.16%2Bpt113cpu-cp38-cp38-linux_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_cluster-1.6.0%2Bpt113cpu-cp38-cp38-linux_x86_64.whl (704 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.9/704.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_spline_conv-1.2.1%2Bpt113cpu-cp38-cp38-linux_x86_64.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-geometric\n","  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.10.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.24.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n","Collecting psutil>=5.8.0\n","  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=31c0a356195370a23eed1cbf71adf250a1af3d3396a6b7d887a991555ffb697f\n","  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n","Successfully built torch-geometric\n","Installing collected packages: torch-spline-conv, torch-scatter, pyg-lib, psutil, torch-sparse, torch-cluster, torch-geometric\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","Successfully installed psutil-5.9.4 pyg-lib-0.1.0+pt113cpu torch-cluster-1.6.0+pt113cpu torch-geometric-2.2.0 torch-scatter-2.1.0+pt113cpu torch-sparse-0.6.16+pt113cpu torch-spline-conv-1.2.1+pt113cpu\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{}}],"source":["!pip install -q --upgrade pip\n","!pip install -q --upgrade jax[cuda11_cudnn805] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n","!pip install -q git+https://www.github.com/google/neural-tangents\n","!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n","!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html"]},{"cell_type":"code","execution_count":null,"id":"sTQTU0QVbHhK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32060,"status":"ok","timestamp":1676833788923,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"sTQTU0QVbHhK","outputId":"643a9f17-82d1-45b8-e11b-affc12baadf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: jaxlib 0.3.25+cuda11.cudnn805\n","Uninstalling jaxlib-0.3.25+cuda11.cudnn805:\n","  Would remove:\n","    /usr/local/lib/python3.8/dist-packages/jaxlib-0.3.25+cuda11.cudnn805.dist-info/*\n","    /usr/local/lib/python3.8/dist-packages/jaxlib/*\n","Proceed (Y/n)? Y\n","  Successfully uninstalled jaxlib-0.3.25+cuda11.cudnn805\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n","Collecting jaxlib==0.4.2+cuda11.cudnn82\n","  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.2%2Bcuda11.cudnn82-cp38-cp38-manylinux2014_x86_64.whl (164.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jaxlib==0.4.2+cuda11.cudnn82) (1.10.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jaxlib==0.4.2+cuda11.cudnn82) (1.24.2)\n","Installing collected packages: jaxlib\n","Successfully installed jaxlib-0.4.2+cuda11.cudnn82\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip uninstall jaxlib\n","#!pip install jaxlib==0.4.2\n","!pip install -U jaxlib==0.4.2+cuda11.cudnn82 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"]},{"cell_type":"code","execution_count":1,"id":"p7-LmT35vXGs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439,"status":"ok","timestamp":1676836884827,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"p7-LmT35vXGs","outputId":"eac598eb-172d-45b0-de7e-fa54723e5123"},"outputs":[{"output_type":"stream","name":"stdout","text":["env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n","env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"]}],"source":["# https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html\n","%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n","#%env JAX_PLATFORMS=cpu\n","%env XLA_PYTHON_CLIENT_ALLOCATOR=platform"]},{"cell_type":"code","execution_count":1,"id":"ZnQH_l9gqFUm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17915,"status":"ok","timestamp":1676875143491,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"ZnQH_l9gqFUm","outputId":"3e5cb2c8-31b6-43f9-b11f-74be5f3baef3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Masterarbeit/two_WL_NTK\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks/Masterarbeit/two_WL_NTK"]},{"cell_type":"code","execution_count":3,"id":"yxczYSzS5XnY","metadata":{"executionInfo":{"elapsed":2936,"status":"ok","timestamp":1676836889727,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"yxczYSzS5XnY"},"outputs":[],"source":["from utils import *\n","from layers import two_wl_aggregation"]},{"cell_type":"code","execution_count":4,"id":"9532531e","metadata":{"executionInfo":{"elapsed":2123,"status":"ok","timestamp":1676836891838,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"9532531e"},"outputs":[],"source":["import numpy\n","import neural_tangents as nt\n","from neural_tangents import stax\n","from jax import numpy as np\n","from jax import random\n","import jax\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.loader import DataLoader\n","import shutil\n","import os"]},{"cell_type":"code","execution_count":5,"id":"cc636972","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1676836891840,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"cc636972"},"outputs":[],"source":["# for input \"kernel_fn(x1, x2, 'ntk', pattern = (p1,p2))\"\n","# the shape of the kernel after the convolution is:\n","# x1 = (b1, h1, w1, c1)\n","# x2 = (b2, h2, w2, c2)\n","# k = (b1, b2, h1, h2, w1, w2) \n","\n","\n","L_branche = stax.serial(\n","    stax.Conv(100, (1,1)),\n","    )\n","\n","Gamma_branche = stax.serial(\n","    stax.Conv(100, (1,1)),\n","    two_wl_aggregation(n_nodes=28),\n",")\n","\n","two_wl_aggregation_layer = stax.serial(\n","    stax.FanOut(2), \n","    stax.parallel(L_branche, Gamma_branche),\n","    stax.FanInSum(),\n","    stax.Relu(),\n","    )\n","\n","\n","init_fn, apply_fn, kernel_fn = stax.serial(\n","    two_wl_aggregation_layer,\n","    two_wl_aggregation_layer,\n","    two_wl_aggregation_layer,\n","    two_wl_aggregation_layer,\n","    two_wl_aggregation_layer,\n","    #two_wl_aggregation_layer,\n","    #two_wl_aggregation_layer,\n","    #two_wl_aggregation_layer,\n","    #two_wl_aggregation_layer,\n","    #two_wl_aggregation_layer, # k = (b1, b2, h1, h2, w1, w2)\n","    stax.GlobalSumPool(), # # k = (b1, b2)\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":6,"id":"PvJtU4WN_AQA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17123,"status":"ok","timestamp":1676836908954,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"PvJtU4WN_AQA","outputId":"0f449797-3570-432b-a16c-83cdc94b58e7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/neural_tangents/_src/stax/branching.py:399: UserWarning: `FanIn` layers assume independent inputs which is not verified in the code. Please make sure to have at least one `Dense` / `Conv` / `GlobalSelfAttention` etc. layer in each branch.\n","  warnings.warn('`FanIn` layers assume independent inputs which is not verified'\n"]},{"output_type":"stream","name":"stdout","text":["CPU times: user 10 s, sys: 1.95 s, total: 12 s\n","Wall time: 17.3 s\n"]}],"source":["#this needs ~9GB gpu-ram, takes ~15s on GPU ~2min on CPU (size 4 using XLA_PYTHON_CLIENT_PREALLOCATE=false)\n","%%time \n","size = 10\n","r = 18\n","i = 0\n","j = 0\n","\n","path = f\"/content/drive/MyDrive/MasterarbeitData/Preprocessed/MUTAG/splits/size_{size}_range_{r}\"\n","\n","x1 = np.load(path + f\"/graphs_edge_features_1_{i*size}_{(1+i)*size}.npy\")\n","x2 = np.load(path + f\"/graphs_edge_features_2_{j*size}_{(1+j)*size}.npy\")\n","p1 = np.load(path + f\"/two_wl_pattern_radius_1_1_{i*size}_{(1+i)*size}.npy\")\n","p2 = np.load(path + f\"/two_wl_pattern_radius_1_2_{j*size}_{(1+j)*size}.npy\")\n","\n","kernel_matrix = kernel_fn(x1, x2, 'ntk', pattern=(p1, p2))"]},{"cell_type":"code","execution_count":7,"id":"N4RhAPlBIA_Q","metadata":{"id":"N4RhAPlBIA_Q","executionInfo":{"status":"ok","timestamp":1676836908955,"user_tz":-60,"elapsed":9,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}}},"outputs":[],"source":["dataset_size = 188\n","size = 10\n","r = 18\n","\n","base_path = f\"/content/drive/MyDrive/MasterarbeitData\"\n","data_path = base_path + f\"/Preprocessed/MUTAG\"\n","split_data_path = data_path + f\"/splits/size_{size}_range_{r}\" \n","kernel_path = base_path + f\"/Kernels/MUTAG/TWO_WL\"\n","if not os.path.exists(kernel_path):\n","    os.makedirs(kernel_path)"]},{"cell_type":"code","execution_count":8,"id":"T9H2HbWVAfgL","metadata":{"id":"T9H2HbWVAfgL","executionInfo":{"status":"ok","timestamp":1676836908956,"user_tz":-60,"elapsed":8,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"}}},"outputs":[],"source":["# clear the kernel folder\n","# shutil.rmtree(kernel_path)"]},{"cell_type":"code","execution_count":9,"id":"i34zfG2FpN9E","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2583561,"status":"ok","timestamp":1676839492510,"user":{"displayName":"Max Hahn","userId":"05735514096494257430"},"user_tz":-60},"id":"i34zfG2FpN9E","outputId":"7fa999ae-e3b6-45f2-fd06-b561ac02b99f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(888, 4)\n","(888, 4)\n","(888, 4)\n","(948, 4)\n","(888, 4)\n","(1140, 4)\n","(888, 4)\n","(904, 4)\n","(888, 4)\n","(964, 4)\n","(888, 4)\n","(1164, 4)\n","(888, 4)\n","(960, 4)\n","(888, 4)\n","(954, 4)\n","(888, 4)\n","(956, 4)\n","(888, 4)\n","(1072, 4)\n","(888, 4)\n","(1276, 4)\n","(888, 4)\n","(800, 4)\n","(888, 4)\n","(922, 4)\n","(888, 4)\n","(880, 4)\n","(888, 4)\n","(744, 4)\n","(888, 4)\n","(870, 4)\n","(888, 4)\n","(1096, 4)\n","(888, 4)\n","(1054, 4)\n","(888, 4)\n","(618, 4)\n","(948, 4)\n","(888, 4)\n","(948, 4)\n","(948, 4)\n","(948, 4)\n","(1140, 4)\n","(948, 4)\n","(904, 4)\n","(948, 4)\n","(964, 4)\n","(948, 4)\n","(1164, 4)\n","(948, 4)\n","(960, 4)\n","(948, 4)\n","(954, 4)\n","(948, 4)\n","(956, 4)\n","(948, 4)\n","(1072, 4)\n","(948, 4)\n","(1276, 4)\n","(948, 4)\n","(800, 4)\n","(948, 4)\n","(922, 4)\n","(948, 4)\n","(880, 4)\n","(948, 4)\n","(744, 4)\n","(948, 4)\n","(870, 4)\n","(948, 4)\n","(1096, 4)\n","(948, 4)\n","(1054, 4)\n","(948, 4)\n","(618, 4)\n","(1140, 4)\n","(888, 4)\n","(1140, 4)\n","(948, 4)\n","(1140, 4)\n","(1140, 4)\n","(1140, 4)\n","(904, 4)\n","(1140, 4)\n","(964, 4)\n","(1140, 4)\n","(1164, 4)\n","(1140, 4)\n","(960, 4)\n","(1140, 4)\n","(954, 4)\n","(1140, 4)\n","(956, 4)\n","(1140, 4)\n","(1072, 4)\n","(1140, 4)\n","(1276, 4)\n","(1140, 4)\n","(800, 4)\n","(1140, 4)\n","(922, 4)\n","(1140, 4)\n","(880, 4)\n","(1140, 4)\n","(744, 4)\n","(1140, 4)\n","(870, 4)\n","(1140, 4)\n","(1096, 4)\n","(1140, 4)\n","(1054, 4)\n","(1140, 4)\n","(618, 4)\n","(904, 4)\n","(888, 4)\n","(904, 4)\n","(948, 4)\n","(904, 4)\n","(1140, 4)\n","(904, 4)\n","(904, 4)\n","(904, 4)\n","(964, 4)\n","(904, 4)\n","(1164, 4)\n","(904, 4)\n","(960, 4)\n","(904, 4)\n","(954, 4)\n","(904, 4)\n","(956, 4)\n","(904, 4)\n","(1072, 4)\n","(904, 4)\n","(1276, 4)\n","(904, 4)\n","(800, 4)\n","(904, 4)\n","(922, 4)\n","(904, 4)\n","(880, 4)\n","(904, 4)\n","(744, 4)\n","(904, 4)\n","(870, 4)\n","(904, 4)\n","(1096, 4)\n","(904, 4)\n","(1054, 4)\n","(904, 4)\n","(618, 4)\n","(964, 4)\n","(888, 4)\n","(964, 4)\n","(948, 4)\n","(964, 4)\n","(1140, 4)\n","(964, 4)\n","(904, 4)\n","(964, 4)\n","(964, 4)\n","(964, 4)\n","(1164, 4)\n","(964, 4)\n","(960, 4)\n","(964, 4)\n","(954, 4)\n","(964, 4)\n","(956, 4)\n","(964, 4)\n","(1072, 4)\n","(964, 4)\n","(1276, 4)\n","(964, 4)\n","(800, 4)\n","(964, 4)\n","(922, 4)\n","(964, 4)\n","(880, 4)\n","(964, 4)\n","(744, 4)\n","(964, 4)\n","(870, 4)\n","(964, 4)\n","(1096, 4)\n","(964, 4)\n","(1054, 4)\n","(964, 4)\n","(618, 4)\n","(1164, 4)\n","(888, 4)\n","(1164, 4)\n","(948, 4)\n","(1164, 4)\n","(1140, 4)\n","(1164, 4)\n","(904, 4)\n","(1164, 4)\n","(964, 4)\n","(1164, 4)\n","(1164, 4)\n","(1164, 4)\n","(960, 4)\n","(1164, 4)\n","(954, 4)\n","(1164, 4)\n","(956, 4)\n","(1164, 4)\n","(1072, 4)\n","(1164, 4)\n","(1276, 4)\n","(1164, 4)\n","(800, 4)\n","(1164, 4)\n","(922, 4)\n","(1164, 4)\n","(880, 4)\n","(1164, 4)\n","(744, 4)\n","(1164, 4)\n","(870, 4)\n","(1164, 4)\n","(1096, 4)\n","(1164, 4)\n","(1054, 4)\n","(1164, 4)\n","(618, 4)\n","(960, 4)\n","(888, 4)\n","(960, 4)\n","(948, 4)\n","(960, 4)\n","(1140, 4)\n","(960, 4)\n","(904, 4)\n","(960, 4)\n","(964, 4)\n","(960, 4)\n","(1164, 4)\n","(960, 4)\n","(960, 4)\n","(960, 4)\n","(954, 4)\n","(960, 4)\n","(956, 4)\n","(960, 4)\n","(1072, 4)\n","(960, 4)\n","(1276, 4)\n","(960, 4)\n","(800, 4)\n","(960, 4)\n","(922, 4)\n","(960, 4)\n","(880, 4)\n","(960, 4)\n","(744, 4)\n","(960, 4)\n","(870, 4)\n","(960, 4)\n","(1096, 4)\n","(960, 4)\n","(1054, 4)\n","(960, 4)\n","(618, 4)\n","(954, 4)\n","(888, 4)\n","(954, 4)\n","(948, 4)\n","(954, 4)\n","(1140, 4)\n","(954, 4)\n","(904, 4)\n","(954, 4)\n","(964, 4)\n","(954, 4)\n","(1164, 4)\n","(954, 4)\n","(960, 4)\n","(954, 4)\n","(954, 4)\n","(954, 4)\n","(956, 4)\n","(954, 4)\n","(1072, 4)\n","(954, 4)\n","(1276, 4)\n","(954, 4)\n","(800, 4)\n","(954, 4)\n","(922, 4)\n","(954, 4)\n","(880, 4)\n","(954, 4)\n","(744, 4)\n","(954, 4)\n","(870, 4)\n","(954, 4)\n","(1096, 4)\n","(954, 4)\n","(1054, 4)\n","(954, 4)\n","(618, 4)\n","(956, 4)\n","(888, 4)\n","(956, 4)\n","(948, 4)\n","(956, 4)\n","(1140, 4)\n","(956, 4)\n","(904, 4)\n","(956, 4)\n","(964, 4)\n","(956, 4)\n","(1164, 4)\n","(956, 4)\n","(960, 4)\n","(956, 4)\n","(954, 4)\n","(956, 4)\n","(956, 4)\n","(956, 4)\n","(1072, 4)\n","(956, 4)\n","(1276, 4)\n","(956, 4)\n","(800, 4)\n","(956, 4)\n","(922, 4)\n","(956, 4)\n","(880, 4)\n","(956, 4)\n","(744, 4)\n","(956, 4)\n","(870, 4)\n","(956, 4)\n","(1096, 4)\n","(956, 4)\n","(1054, 4)\n","(956, 4)\n","(618, 4)\n","(1072, 4)\n","(888, 4)\n","(1072, 4)\n","(948, 4)\n","(1072, 4)\n","(1140, 4)\n","(1072, 4)\n","(904, 4)\n","(1072, 4)\n","(964, 4)\n","(1072, 4)\n","(1164, 4)\n","(1072, 4)\n","(960, 4)\n","(1072, 4)\n","(954, 4)\n","(1072, 4)\n","(956, 4)\n","(1072, 4)\n","(1072, 4)\n","(1072, 4)\n","(1276, 4)\n","(1072, 4)\n","(800, 4)\n","(1072, 4)\n","(922, 4)\n","(1072, 4)\n","(880, 4)\n","(1072, 4)\n","(744, 4)\n","(1072, 4)\n","(870, 4)\n","(1072, 4)\n","(1096, 4)\n","(1072, 4)\n","(1054, 4)\n","(1072, 4)\n","(618, 4)\n","(1276, 4)\n","(888, 4)\n","(1276, 4)\n","(948, 4)\n","(1276, 4)\n","(1140, 4)\n","(1276, 4)\n","(904, 4)\n","(1276, 4)\n","(964, 4)\n","(1276, 4)\n","(1164, 4)\n","(1276, 4)\n","(960, 4)\n","(1276, 4)\n","(954, 4)\n","(1276, 4)\n","(956, 4)\n","(1276, 4)\n","(1072, 4)\n","(1276, 4)\n","(1276, 4)\n","(1276, 4)\n","(800, 4)\n","(1276, 4)\n","(922, 4)\n","(1276, 4)\n","(880, 4)\n","(1276, 4)\n","(744, 4)\n","(1276, 4)\n","(870, 4)\n","(1276, 4)\n","(1096, 4)\n","(1276, 4)\n","(1054, 4)\n","(1276, 4)\n","(618, 4)\n","(800, 4)\n","(888, 4)\n","(800, 4)\n","(948, 4)\n","(800, 4)\n","(1140, 4)\n","(800, 4)\n","(904, 4)\n","(800, 4)\n","(964, 4)\n","(800, 4)\n","(1164, 4)\n","(800, 4)\n","(960, 4)\n","(800, 4)\n","(954, 4)\n","(800, 4)\n","(956, 4)\n","(800, 4)\n","(1072, 4)\n","(800, 4)\n","(1276, 4)\n","(800, 4)\n","(800, 4)\n","(800, 4)\n","(922, 4)\n","(800, 4)\n","(880, 4)\n","(800, 4)\n","(744, 4)\n","(800, 4)\n","(870, 4)\n","(800, 4)\n","(1096, 4)\n","(800, 4)\n","(1054, 4)\n","(800, 4)\n","(618, 4)\n","(922, 4)\n","(888, 4)\n","(922, 4)\n","(948, 4)\n","(922, 4)\n","(1140, 4)\n","(922, 4)\n","(904, 4)\n","(922, 4)\n","(964, 4)\n","(922, 4)\n","(1164, 4)\n","(922, 4)\n","(960, 4)\n","(922, 4)\n","(954, 4)\n","(922, 4)\n","(956, 4)\n","(922, 4)\n","(1072, 4)\n","(922, 4)\n","(1276, 4)\n","(922, 4)\n","(800, 4)\n","(922, 4)\n","(922, 4)\n","(922, 4)\n","(880, 4)\n","(922, 4)\n","(744, 4)\n","(922, 4)\n","(870, 4)\n","(922, 4)\n","(1096, 4)\n","(922, 4)\n","(1054, 4)\n","(922, 4)\n","(618, 4)\n","(880, 4)\n","(888, 4)\n","(880, 4)\n","(948, 4)\n","(880, 4)\n","(1140, 4)\n","(880, 4)\n","(904, 4)\n","(880, 4)\n","(964, 4)\n","(880, 4)\n","(1164, 4)\n","(880, 4)\n","(960, 4)\n","(880, 4)\n","(954, 4)\n","(880, 4)\n","(956, 4)\n","(880, 4)\n","(1072, 4)\n","(880, 4)\n","(1276, 4)\n","(880, 4)\n","(800, 4)\n","(880, 4)\n","(922, 4)\n","(880, 4)\n","(880, 4)\n","(880, 4)\n","(744, 4)\n","(880, 4)\n","(870, 4)\n","(880, 4)\n","(1096, 4)\n","(880, 4)\n","(1054, 4)\n","(880, 4)\n","(618, 4)\n","(744, 4)\n","(888, 4)\n","(744, 4)\n","(948, 4)\n","(744, 4)\n","(1140, 4)\n","(744, 4)\n","(904, 4)\n","(744, 4)\n","(964, 4)\n","(744, 4)\n","(1164, 4)\n","(744, 4)\n","(960, 4)\n","(744, 4)\n","(954, 4)\n","(744, 4)\n","(956, 4)\n","(744, 4)\n","(1072, 4)\n","(744, 4)\n","(1276, 4)\n","(744, 4)\n","(800, 4)\n","(744, 4)\n","(922, 4)\n","(744, 4)\n","(880, 4)\n","(744, 4)\n","(744, 4)\n","(744, 4)\n","(870, 4)\n","(744, 4)\n","(1096, 4)\n","(744, 4)\n","(1054, 4)\n","(744, 4)\n","(618, 4)\n","(870, 4)\n","(888, 4)\n","(870, 4)\n","(948, 4)\n","(870, 4)\n","(1140, 4)\n","(870, 4)\n","(904, 4)\n","(870, 4)\n","(964, 4)\n","(870, 4)\n","(1164, 4)\n","(870, 4)\n","(960, 4)\n","(870, 4)\n","(954, 4)\n","(870, 4)\n","(956, 4)\n","(870, 4)\n","(1072, 4)\n","(870, 4)\n","(1276, 4)\n","(870, 4)\n","(800, 4)\n","(870, 4)\n","(922, 4)\n","(870, 4)\n","(880, 4)\n","(870, 4)\n","(744, 4)\n","(870, 4)\n","(870, 4)\n","(870, 4)\n","(1096, 4)\n","(870, 4)\n","(1054, 4)\n","(870, 4)\n","(618, 4)\n","(1096, 4)\n","(888, 4)\n","(1096, 4)\n","(948, 4)\n","(1096, 4)\n","(1140, 4)\n","(1096, 4)\n","(904, 4)\n","(1096, 4)\n","(964, 4)\n","(1096, 4)\n","(1164, 4)\n","(1096, 4)\n","(960, 4)\n","(1096, 4)\n","(954, 4)\n","(1096, 4)\n","(956, 4)\n","(1096, 4)\n","(1072, 4)\n","(1096, 4)\n","(1276, 4)\n","(1096, 4)\n","(800, 4)\n","(1096, 4)\n","(922, 4)\n","(1096, 4)\n","(880, 4)\n","(1096, 4)\n","(744, 4)\n","(1096, 4)\n","(870, 4)\n","(1096, 4)\n","(1096, 4)\n","(1096, 4)\n","(1054, 4)\n","(1096, 4)\n","(618, 4)\n","(1054, 4)\n","(888, 4)\n","(1054, 4)\n","(948, 4)\n","(1054, 4)\n","(1140, 4)\n","(1054, 4)\n","(904, 4)\n","(1054, 4)\n","(964, 4)\n","(1054, 4)\n","(1164, 4)\n","(1054, 4)\n","(960, 4)\n","(1054, 4)\n","(954, 4)\n","(1054, 4)\n","(956, 4)\n","(1054, 4)\n","(1072, 4)\n","(1054, 4)\n","(1276, 4)\n","(1054, 4)\n","(800, 4)\n","(1054, 4)\n","(922, 4)\n","(1054, 4)\n","(880, 4)\n","(1054, 4)\n","(744, 4)\n","(1054, 4)\n","(870, 4)\n","(1054, 4)\n","(1096, 4)\n","(1054, 4)\n","(1054, 4)\n","(1054, 4)\n","(618, 4)\n","(618, 4)\n","(888, 4)\n","(618, 4)\n","(948, 4)\n","(618, 4)\n","(1140, 4)\n","(618, 4)\n","(904, 4)\n","(618, 4)\n","(964, 4)\n","(618, 4)\n","(1164, 4)\n","(618, 4)\n","(960, 4)\n","(618, 4)\n","(954, 4)\n","(618, 4)\n","(956, 4)\n","(618, 4)\n","(1072, 4)\n","(618, 4)\n","(1276, 4)\n","(618, 4)\n","(800, 4)\n","(618, 4)\n","(922, 4)\n","(618, 4)\n","(880, 4)\n","(618, 4)\n","(744, 4)\n","(618, 4)\n","(870, 4)\n","(618, 4)\n","(1096, 4)\n","(618, 4)\n","(1054, 4)\n","(618, 4)\n","(618, 4)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/neural_tangents/_src/stax/branching.py:399: UserWarning: `FanIn` layers assume independent inputs which is not verified in the code. Please make sure to have at least one `Dense` / `Conv` / `GlobalSelfAttention` etc. layer in each branch.\n","  warnings.warn('`FanIn` layers assume independent inputs which is not verified'\n"]}],"source":["# at some point this allways fails with 15gb gpu memory\n","# fails always for some function in utils\n","# can we make those function more memory efficient?\n","\n","# with XLA_PYTHON_CLIENT_ALLOCATOR=platform this seems to stay below 5GB \n","# GPU-RAM usage for size=4\n","\n","# calculate kernel from saved preprocessed data\n","for i in range(r+1):\n","  for j in range(r+1):\n","\n","    l = lambda x : x*size \n","    h = lambda x : (1+x)*size if (not x == r) else dataset_size-1\n","\n","    x1 = np.load(split_data_path + f\"/graphs_edge_features_1_{l(i)}_{h(i)}.npy\")\n","    x2 = np.load(split_data_path + f\"/graphs_edge_features_2_{l(j)}_{h(j)}.npy\")\n","    p1 = np.load(split_data_path + f\"/two_wl_pattern_radius_1_1_{l(i)}_{h(i)}.npy\")\n","    p2 = np.load(split_data_path + f\"/two_wl_pattern_radius_1_2_{l(j)}_{h(j)}.npy\")\n","\n","    print(p1.shape)\n","    print(p2.shape)\n","\n","    kernel_matrix = kernel_fn(x1, x2, 'ntk', pattern=(p1, p2))\n","    np.save(kernel_path + f\"/NTK_{h(i)}_{h(j)}\", kernel_matrix)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1H0cVDyGK843qOVhwHknCNwPPtbaqnqar","timestamp":1675937427001}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":5}